{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, classification_report, recall_score, confusion_matrix, make_scorer, fbeta_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "#my_details \n",
    "__author__ = \"sreetam dev\"\n",
    "__email__  = \"sreetamkumardev@gmail.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loading_files_df(file):\n",
    "    '''stores csv file as dataframe'''\n",
    "    df_bank = pd.read_csv(file, sep = \";\")\n",
    "    return df_bank\n",
    "\n",
    "def removing_instances(feature, df):\n",
    "    '''removing duplicate instances and duration column from the file'''\n",
    "    df      = df.drop_duplicates()\n",
    "    df_bank = df.drop(feature,axis =1)\n",
    "    return df_bank\n",
    "\n",
    "def grouping_basic_education(feature,df):\n",
    "    '''assigning basic education feature in to one common feature'''\n",
    "    df[feature] = np.where(df[feature]=='basic.9y','Basic', df[feature])\n",
    "    df[feature] = np.where(df[feature]=='basic.6y','Basic', df[feature])\n",
    "    df[feature] = np.where(df[feature]=='basic.4y','Basic', df[feature])\n",
    "    return df\n",
    "\n",
    "def mapping_target(feature,df):\n",
    "    '''mapping categorical values to binary values for the target feature'''\n",
    "    df[feature]       = df[feature].map({'yes':1, 'no':0})\n",
    "    df_cat_feat       = df.describe(include =['O']).columns\n",
    "    df                = pd.get_dummies(data = df , columns = df_cat_feat)\n",
    "    df_bank_processed = df.copy()\n",
    "    return df_bank_processed\n",
    "\n",
    "def fixing_skewness(feature,df):\n",
    "    '''transforming features that add to skewness'''\n",
    "    '''perform this step for n times if n features have to be transformed'''\n",
    "    df[feature] = np.log(df[feature]+1)\n",
    "    return df\n",
    "\n",
    "def scaling_features(df):\n",
    "    '''scaling features before modelling to have uniform measurement scale in terms of central tendency'''\n",
    "    scaler          = MinMaxScaler() \n",
    "    df_nr_feat      = df.describe(include = [np.number]).columns\n",
    "    df[ df_nr_feat] = scaler.fit_transform(df[df_nr_feat])\n",
    "    return df\n",
    "\n",
    "def extracting_feature(target,df):\n",
    "    '''storing our  features as  X '''\n",
    "    X = df.drop([target],1).values\n",
    "    return X\n",
    "\n",
    "def extracting_target(target,df):\n",
    "    '''storing our target as y  '''\n",
    "    y = df[target].values\n",
    "    return y\n",
    "\n",
    "def split_features_target(X,y):\n",
    "    '''forming our train and test instances'''\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2,random_state=42,stratify=y)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "    \n",
    "def sampling_feature_target(target,X_train, y_train,df):\n",
    "    '''preparing our sampled instances and storing them as datasets'''\n",
    "    X_columns    = df.drop([target],1).columns\n",
    "    smote_tomek  = SMOTETomek(sampling_strategy = 'auto')\n",
    "    X_smt, y_smt = smote_tomek.fit_sample(X_train, y_train)\n",
    "    df_X_smt     = pd.DataFrame(data = X_smt, columns = X_columns)\n",
    "    df_y_smt     = pd.DataFrame(data = y_smt, columns = [target])\n",
    "    return X_smt, y_smt, df_X_smt, df_y_smt\n",
    "\n",
    "def inspecting_model(X_smt,y_smt,X_t,model):\n",
    "    \n",
    "    '''pass sampled X ,y and X_test instances'''\n",
    "    rfe                      = RFE(model,n_features_to_select = 20)\n",
    "    X_smt_rfe                = rfe.fit_transform(X_smt, y_smt)\n",
    "    X_test_rfe               = rfe.transform(X_t)\n",
    "    # model  = model.fit(X_smt_rfe,y_smt)\n",
    "    no_stratified_folds      = StratifiedKFold(n_splits = 5, random_state= 1 )\n",
    "    crossval_score_model     = cross_val_score(model,X_smt_rfe ,y_smt, scoring = 'accuracy', cv = no_stratified_folds,n_jobs= 1, error_score='raise'  )\n",
    "    Model                    = print(model)\n",
    "    Accuracy_Model           = np.mean(crossval_score_model)\n",
    "    Standard_Deviation_Model = np.std(crossval_score_model)\n",
    "    return  Accuracy_Model, Standard_Deviation_Model \n",
    "\n",
    "def initiating_final_model(X_smt,y_smt,X_t,y_t):\n",
    "    '''pass  X smote sample ,y smote sample and X_test instances'''\n",
    "    \n",
    "    model_rfc       = RandomForestClassifier(n_estimators= 200, max_features= 'auto', max_depth= 20 , criterion= 'gini')\n",
    "    rfe             = RFE(model_rfc,n_features_to_select = 5)\n",
    "    X_smt_rfe       = rfe.fit_transform(X_smt, y_smt)\n",
    "    X_test_rfe      = rfe.transform(X_t)\n",
    "    model_rfc.fit(X_smt_rfe,y_smt)\n",
    "    y_pred          = model_rfc.predict(X_test_rfe)\n",
    "    conf_matrix_rfe = confusion_matrix(y_t,y_pred)\n",
    "    classi_repo     = classification_report(y_t, y_pred)\n",
    "    return model_rfc, rfe, X_test_rfe, y_pred, conf_matrix_rfe,classi_repo \n",
    "\n",
    "def metrics_model(y_t, y_pred):\n",
    "    '''fetching confusion matrix, accuracy, precision and recall'''\n",
    "    \n",
    "    \n",
    "    conf_matrix_rfe = confusion_matrix(y_t,y_pred)\n",
    "    TP              = conf_matrix_rfe[1,1]\n",
    "    FN              = conf_matrix_rfe[1,0]\n",
    "    FP              = conf_matrix_rfe[0,1]\n",
    "    TN              = conf_matrix_rfe[0,0]\n",
    "    accuracy_sc     = round(metrics.accuracy_score(y_t, y_pred),2)\n",
    "    recall_sc       = round(metrics.recall_score(y_t, y_pred),2)\n",
    "    precision_sc    = round(metrics.precision_score(y_t, y_pred),2)\n",
    "    \n",
    "    \n",
    "    return  TP, FN, FP, TN, conf_matrix_rfe,accuracy_sc,recall_sc, precision_sc\n",
    "\n",
    "def model_threshold(model, X_test_rfe,y_t,y_pred):\n",
    "    '''altering threshold of prediction probabilities'''\n",
    "    y_pred_prob           = model.predict_proba(X_test_rfe)[:,1]\n",
    "    y_pred_threshold      = np.where(y_pred_prob< 0.45, 0 , 1)\n",
    "    thres_conf_matrix_rfe = confusion_matrix(y_t,y_pred)\n",
    "    \n",
    "    TP_thres = thres_conf_matrix_rfe[1,1]\n",
    "    FN_thres = thres_conf_matrix_rfe[1,0]\n",
    "    FP_thres = thres_conf_matrix_rfe[0,1]\n",
    "    TN_thres = thres_conf_matrix_rfe[0,0]\n",
    "    \n",
    "\n",
    "    thres_accuracy_score  = round(metrics.accuracy_score(y_t, y_pred),2)\n",
    "    thres_recall_score    = round(metrics.recall_score(y_t, y_pred),2)\n",
    "    thres_precision_score = round(metrics.precision_score(y_t, y_pred),2)\n",
    "    \n",
    "    \n",
    "    return TP_thres, FN_thres, FP_thres, TN_thres, thres_conf_matrix_rfe,thres_accuracy_score, thres_recall_score, thres_precision_score\n",
    "\n",
    "def selected_features(rfe, df_X_smt):\n",
    "    '''findind out the important features for the model'''\n",
    "    columns             = df_X_smt.columns\n",
    "    val                 = pd.Series(rfe.support_,index = columns)\n",
    "    features_chosen_rfe = val[val==True].index \n",
    "    \n",
    "    return features_chosen_rfe\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "'''1. savig the dataset as dataframe'''\n",
    "df_bank = loading_files_df(\"bank-additional-full.csv\")\n",
    "\n",
    "'''2. removing duplicate instances and the duration column'''\n",
    "df_bank = removing_instances('duration', df_bank)\n",
    "\n",
    "'''3. grouping the basic education instances into one'''\n",
    "df_bank = grouping_basic_education(\"education\",df_bank)\n",
    "\n",
    "'''4. mapping the the target column values with binary values'''\n",
    "\n",
    "df_bank_processed = mapping_target('y',df_bank)\n",
    "\n",
    "'''5. handling skewness asscoaited with features'''\n",
    "df_bank_processed = fixing_skewness('age',df_bank_processed)\n",
    "df_bank_processed = fixing_skewness('campaign',df_bank_processed)\n",
    "\n",
    "'''6.Scaling numerical features'''\n",
    "df_bank_processed = scaling_features(df_bank_processed)\n",
    "\n",
    "'''7.Storing our features as  X'''\n",
    "X = extracting_feature('y',df_bank_processed)\n",
    "\n",
    "'''8.storing our target  as y '''\n",
    "y = extracting_target('y',df_bank_processed)\n",
    "\n",
    "'''9.train and test instances. Note: maintain the order of the variables'''\n",
    "X_train, X_test, y_train, y_test = split_features_target(X,y)\n",
    "\n",
    "'''10.sampled instances and their dataframes'''\n",
    "X_smt, y_smt, df_X_smt, df_y_smt = sampling_feature_target('y',X_train, y_train,df_bank_processed)\n",
    "\n",
    "'''11.Preparing models for sampled X ,y and X_test instances'''\n",
    "model_lr   = LogisticRegression(random_state = 42, penalty = \"l2\")\n",
    "model_rfc  = RandomForestClassifier(n_estimators= 200, max_features= 'auto', max_depth= 20 , criterion= 'gini')\n",
    "list_model = [model_lr, model_rfc]\n",
    "    \n",
    "for model in list_model:\n",
    "    Accuracy_Model, Standard_Deviation_Model = inspecting_model(X_smt, y_smt,X_test,model)\n",
    "    print(\"For the model accuracy is {} and standard devaition is {}\".format( Accuracy_Model, Standard_Deviation_Model))\n",
    "\n",
    "\n",
    "'''12. X smote sample ,y smote sample and X_test instances'''\n",
    "\n",
    "model_rfc, rfe, X_test_rfe, y_pred, conf_matrix_rfe,classi_repo = initiating_final_model(X_smt,y_smt,X_test,y_test)\n",
    "\n",
    "'''13.fetching confusion matrix, accuracy, precision and recall'''\n",
    "\n",
    "TP, FN, FP, TN, conf_matrix_rfe,accuracy_sc,recall_sc, precision_sc = metrics_model(y_test, y_pred)\n",
    "\n",
    "'''14. altering threshold of the predicted probabilities'''\n",
    "\n",
    "TP_thres, FN_thres, FP_thres, TN_thres, thres_conf_matrix_rfe,thres_accuracy_score, thres_recall_score, thres_precision_score = model_threshold(model_rfc,X_test_rfe,y_test,y_pred)\n",
    "\n",
    "\n",
    "'''15.finding out the features for prediction'''\n",
    "\n",
    "features_chosen_rfe = selected_features(rfe, df_X_smt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
